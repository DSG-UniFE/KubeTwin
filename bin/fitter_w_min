#!/usr/bin/env ruby

begin
  require 'kube_twin'
  require 'mhl'
  require 'logger'
  require 'pycall'
  require 'pycall/import'
  include PyCall::Import
  require 'csv'
rescue LoadError
  require 'rubygems'
  require 'kube_twin'
  require 'mhl'
end

def do_abort(message)
    abort <<-EOS.gsub(/^\s+\|/, '')
      |#{message}
      |
      |Usage:
      |    #{File.basename(__FILE__)} simulator_config_file testbed_file n
      |
    EOS
  end

if ARGV.length < 3
  do_abort("Uncompleted parameters")
end
  
  
if File.expand_path(__FILE__) == File.expand_path($0)
    # make sure both required arguments were given
    case ARGV.size
    when 0 then
      do_abort("Missing simulator configuration files!")
    end
  
    # make sure simulator config file exists
    unless File.exists? ARGV[0]
      do_abort("Invalid simulator configuration file!")
    end
end

unless File.exists? ARGV[1]
  do_abort("Invalid dataset log")
end

$n = ARGV[2].to_i

# GMM with at least 3 components
#raise "GMM components should be greater than 3" if $n < 3

$params = $n * 3 - 1 # weight mu sigma for each component
# - 1 --> array indexes start from 0

puts "n #{$n} params #{$params}"

# pycall import
pyfrom :scipy, import: :stats
pyfrom :scipy, import: :special
PyCall.import_module("numpy")

# load simulation configuration
time = Time.now.strftime('%Y%m%d%H%M%S')
results_dirname = "#{time}_results"

# create an output directory if it does not exist
Dir.mkdir(results_dirname) unless File.exist?(results_dirname)

GA_LOG = "#{results_dirname}/fitter_log_#{time}_#{$n}.log"

File.delete(GA_LOG) if File.exist?(GA_LOG)
ga_logger = Logger.new(GA_LOG)
ga_logger.level = Logger::INFO

sim_conf = KUBETWIN::Configuration.load_from_file(ARGV[0])
msc = sim_conf.microservice_types

# open the log only once
k8s_log = CSV.parse(File.read(ARGV[1]), headers: true)
k8s_ttr = k8s_log.by_col[1].map(&:to_f) # get the ttr column

# ms1 ttr
k8s_ms1 = CSV.parse(File.read(ARGV[3]), headers: true)
ms1_ttr = k8s_ms1.by_col[0].map(&:to_f) # get the ttr column
puts "MS1: #{ms1_ttr.length} #{ms1_ttr.max} #{ms1_ttr.min}"

# ms2 ttr
k8s_ms2 = CSV.parse(File.read(ARGV[4]), headers: true)
ms2_ttr = k8s_ms2.by_col[0].map(&:to_f) # get the ttr column
# ms2_ttr = ms2_ttr.select{|e| ! e.nil?}.collect {|e| e * 1E3}

puts "MS2: #{ms2_ttr.length} #{ms2_ttr.max} #{ms2_ttr.min}"
puts "TTR: #{k8s_ttr.length} #{k8s_ttr.max} #{k8s_ttr.min}"


$microservice_types = sim_conf.microservice_types
$n_ms = $microservice_types.length

puts "Number of microservices #{$n_ms}"

$seed = 12345

def encode_service_time_conf(x, n_ms)

  # for each micro-servce
  config = {}

  # simple Gaussian model
  if $n == 1
    #parameters = 2 # mu and sigma
    # if we want just a gaussian here
    x.each_slice($params).to_a.each_with_index do |ms, msi|
      microservice_name = $microservice_types.keys[msi]
      config[microservice_name] = { distribution: :gaussian, args: {mean: ms[0], sd: ms[1], seed: $seed}}
    end
    #puts config
    return config
  end
  # otherwise GMM model
  x.each_slice($params).to_a.each_with_index do |ms, msi|

    w_last = 1
    (0..($params - 3)).select {|pi| pi % 3 == 0}.each do |p| 
      w_last -= ms[p]
    end

    # w_last = 0 if w_last < 0 # reject negative probabilities  
    # or normalize the sum of tha absolute values to 1?
    return nil if w_last < 0

    # clone the component allocation
    y = ms.clone
    y.insert($params - 2, w_last)

    microservice_name = $microservice_types.keys[msi]
    config[microservice_name] = { distribution: :mixture, args: 
      ERV::GaussianMixtureHelper.RawParametersToMixtureArgsSeed(*y, $seed)
    }
  end
  config
end

to_optimize = lambda do |component_allocation|

    res = 0
    penalty = 0

    # load simulation configuration
    conf = KUBETWIN::Configuration.load_from_file(ARGV[0])
    msc = sim_conf.microservice_types
    processing_time = encode_service_time_conf(component_allocation, msc.keys.length)
    
    if processing_time.nil?
      penalty += Float::INFINITY
    else
      processing_time.each do |ms_name, ms_time_dist|
        # puts msc
        msc[ms_name][:service_time_distribution][:mec] = ms_time_dist
        # create a simulator and launch it
      end
        
      sim = KUBETWIN::KSimulation.new(configuration: conf,
                                      evaluator: KUBETWIN::Evaluator.new(conf),
                                      results_dir: results_dirname)
      benchmark, bms1, bms2 = sim.evaluate_allocation(nil, nil, msc)

      # evaluate bench here

      sim_log = CSV.parse(File.read(benchmark), headers: true)
      sim_ttr = sim_log.by_col[1].map(&:to_f)

      ms1_log = CSV.parse(File.read(bms1), headers: true)
      sim_ms1_ttr = ms1_log.by_col[1].map(&:to_f)

      ms2_log = CSV.parse(File.read(bms2), headers: true)
      sim_ms2_ttr = ms2_log.by_col[1].map(&:to_f)

      if sim_ttr.length != k8s_ttr.length
        penalty += Float::INFINITY
      else
        begin
          w_e2e = stats.wilcoxon(k8s_ttr, sim_ttr)
          #kl_t = special.kl_div(k8s_ttr, sim_ttr)
          #puts "#{kl_t}"
          # puts "#{w_e2e}"
          ev = k8s_ttr.length * (k8s_ttr.length + sim_ttr.length - 1) / 2.0

          if w_e2e.pvalue.to_f >= 0.05
            puts "Reqs: #{sim_ttr.length} W statistic: #{w_e2e.statistic.to_f} pvalue: #{w_e2e.pvalue.to_f} ev: #{ev} #{(w_e2e.statistic.to_f - ev).abs}" 
            puts "Mean: #{sim_ttr.sum /  sim_ttr.length}"
            #res = (w_e2e.statistic.to_f - ev).abs
          else 
            penalty += 1E5
          end

          res = (w_e2e.statistic.to_f - ev).abs

          # W for ms1 and ms2?
          ev_ms1 = ms1_ttr.length * (ms1_ttr.length + sim_ms1_ttr.length - 1) / 2.0
          ev_ms2 = ms2_ttr.length * (ms2_ttr.length + sim_ms2_ttr.length - 1) / 2.0

          # historical data on ms1 and ms2 is lower than 1000
          pop_data = [ms1_ttr.length, sim_ms1_ttr.length].min
          w_ms1 = stats.wilcoxon(ms1_ttr[0, pop_data], sim_ms1_ttr[0, pop_data])
          w_ms2 = stats.wilcoxon(ms2_ttr[0, pop_data], sim_ms2_ttr[0, pop_data])

          # just some print here
          if w_ms1.pvalue.to_f >= 0.05
            puts "WMS1 statistic: #{w_ms1.statistic.to_f} pvalue: #{w_ms1.pvalue.to_f} ev: #{ev} #{(w_ms1.statistic.to_f - ev_ms1).abs}" 
          else
            penalty += 1E5
          end
          if w_ms2.pvalue.to_f >= 0.05
            puts "WMS2 statistic: #{w_ms2.statistic.to_f} pvalue: #{w_ms2.pvalue.to_f} ev: #{ev} #{(w_ms2.statistic.to_f - ev_ms2).abs}" 
          else
            penalty += 1E5
          end
          # missing weights
          res += (w_ms1.statistic.to_f - ev_ms1).abs + (w_ms2.statistic.to_f - ev_ms2).abs
        rescue => e
          puts("Rescued execption #{e}")
          penalty += Float::INFINITY
        end
      end
      File.delete(benchmark)
      File.delete(bms1)
      File.delete(bms2)
    end

    res += penalty
    #puts "#{res}"
    -res
end

solver_conf = {
  #num_swarms: 6,
  swarm_size: 50,
  logger: ga_logger,
  constraints: {
    min: ([0.0, 5E-3, 5E-3] * ($n-1) + [5E-3, 5E-3]) * $n_ms,
    max: ([1.0, 0.10, 0.10] * ($n-1) + [0.10, 0.10]) *$n_ms,
  },
  exit_condition: lambda {|gen, best | gen >= 100  },
  log_level: :info,
}

solver = MHL::QuantumPSOSolver.new(solver_conf)
best = solver.solve(to_optimize, {concurrent: false})

puts best

# then call the bench function to look for results

to_bench = lambda do |component_allocation|
  res = 0
  conf = KUBETWIN::Configuration.load_from_file(ARGV[0])
  msc = sim_conf.microservice_types
  processing_time = encode_service_time_conf(component_allocation, msc.keys.length)
  
  if processing_time.nil?
    res = 1E+195
  else
    processing_time.each do |ms_name, ms_time_dist|
      msc[ms_name][:service_time_distribution][:mec] = ms_time_dist
    end

    puts "#{msc}"

    sim = KUBETWIN::KSimulation.new(configuration: conf,
                                evaluator: KUBETWIN::Evaluator.new(conf),
                                results_dir: results_dirname)
    benchmark, bms1, bms2 = sim.evaluate_allocation(nil, nil, msc)

    sim_log = CSV.parse(File.read(benchmark), headers: true)
    sim_ttr = sim_log.by_col[1].map(&:to_f)

    ms1_log = CSV.parse(File.read(bms1), headers: true)
    sim_ms1_ttr = ms1_log.by_col[1].map(&:to_f)

    ms2_log = CSV.parse(File.read(bms2), headers: true)
    sim_ms2_ttr = ms2_log.by_col[1].map(&:to_f)

    w_e2e = stats.wilcoxon(k8s_ttr, sim_ttr)
    ga_logger.info "TTR file #{benchmark}"
    puts "Reqs: #{sim_ttr.length} W statistic: #{w_e2e.statistic.to_f} pvalue: #{w_e2e.pvalue.to_f}" 
    puts "Mean: #{sim_ttr.sum /  sim_ttr.length}"
    ga_logger.info "Reqs: #{sim_ttr.length} W statistic: #{w_e2e.statistic.to_f} pvalue: #{w_e2e.pvalue.to_f}" 
    ga_logger.info "Mean: #{sim_ttr.sum /  sim_ttr.length}"
    pop_data = [ms1_ttr.length, sim_ms1_ttr.length].min
    w_ms1 = stats.wilcoxon(ms1_ttr[0, pop_data], sim_ms1_ttr[0, pop_data])
    w_ms2 = stats.wilcoxon(ms2_ttr[0, pop_data], sim_ms2_ttr[0, pop_data])

    puts "WMS1 statistic: #{w_ms1.statistic.to_f} pvalue: #{w_ms1.pvalue.to_f}" 
    puts "WMS2 statistic: #{w_ms2.statistic.to_f} pvalue: #{w_ms2.pvalue.to_f}" 
    ga_logger.info "WMS1 statistic: #{w_ms1.statistic.to_f} pvalue: #{w_ms1.pvalue.to_f}" 
    ga_logger.info "WMS2 statistic: #{w_ms2.statistic.to_f} pvalue: #{w_ms2.pvalue.to_f}" 
  end
  res
end

to_bench.call(best[:position])

puts "exiting"
exit 0

